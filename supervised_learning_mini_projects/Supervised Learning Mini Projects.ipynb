{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the projects for supervised learning for Slide Rule's Data Science Intensive Program which are taken from lectures from Udacity's Intro to Machine Learning Course. The projects cover the Naive Bayes, SVM, and Decision Trees algorithms. They were originally separate, but I thought it would be better to combine them since they all dealt with the same data. The goal is to try to predict the author of an email based on the email's contents.\n",
    "\n",
    "Further details on each project can be found here:\n",
    "\n",
    "Naive Bayes: https://www.udacity.com/course/viewer#!/c-ud120/l-2254358555/m-2959448580\n",
    "\n",
    "SVM: https://www.udacity.com/course/viewer#!/c-ud120/l-2252188570/e-3020238710/m-3037398541\n",
    "\n",
    "Decision Trees: https://www.udacity.com/course/viewer#!/c-ud120/l-2258728540/m-2987588597\n",
    "\n",
    "Most of the code below is a reproduction of the project templates outlined by Udacity. One major difference is that I adapted the code for Python 3. These templates can be found here:\n",
    "\n",
    "https://github.com/udacity/ud120-projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Original: https://github.com/udacity/ud120-projects/blob/master/tools/email_preprocess.py\n",
    "\n",
    "import pickle\n",
    "import numpy\n",
    "\n",
    "from sklearn import cross_validation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "\n",
    "def preprocess(words_file = r\"C:\\Users\\Gordon\\Documents\\Projects\\ud120-projects\\tools\\word_data.pkl\", \n",
    "               authors_file=r\"C:\\Users\\Gordon\\Documents\\Projects\\ud120-projects\\tools\\email_authors.pkl\"):\n",
    "    \"\"\" \n",
    "        this function takes a pre-made list of email texts (by default word_data.pkl)\n",
    "        and the corresponding authors (by default email_authors.pkl) and performs\n",
    "        a number of preprocessing steps:\n",
    "            -- splits into training/testing sets (10% testing)\n",
    "            -- vectorizes into tfidf matrix\n",
    "            -- selects/keeps most helpful features\n",
    "\n",
    "        after this, the features and labels are put into numpy arrays, which play nice with sklearn functions\n",
    "\n",
    "        4 objects are returned:\n",
    "            -- training/testing features\n",
    "            -- training/testing labels\n",
    "    \"\"\"\n",
    "\n",
    "    ### the words (features) and authors (labels), already largely preprocessed\n",
    "    ### this preprocessing will be repeated in the text learning mini-project\n",
    "    authors_file_handler = open(authors_file, 'rb')\n",
    "    authors = pickle.load(authors_file_handler)\n",
    "    authors_file_handler.close()\n",
    "\n",
    "    words_file_handler = open(words_file, 'rb')\n",
    "    word_data = pickle.load(words_file_handler)\n",
    "    words_file_handler.close()\n",
    "\n",
    "    ### test_size is the percentage of events assigned to the test set (remainder go into training)\n",
    "    features_train, features_test, labels_train, labels_test = cross_validation.train_test_split(word_data, \n",
    "                                                                                                 authors, \n",
    "                                                                                                 test_size=0.1, \n",
    "                                                                                                 random_state=42)\n",
    "\t\n",
    "    ### text vectorization--go from strings to lists of numbers\n",
    "    vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5,\n",
    "                                 stop_words='english')\n",
    "    features_train_transformed = vectorizer.fit_transform(features_train)\n",
    "    features_test_transformed  = vectorizer.transform(features_test)\n",
    "\n",
    "    ### feature selection, because text is super high dimensional and \n",
    "    ### can be really computationally chewy as a result\n",
    "    selector = SelectPercentile(f_classif, percentile=10)\n",
    "\t#selector = SelectPercentile(f_classif, percentile=1) \n",
    "    selector.fit(features_train_transformed, labels_train)\n",
    "    features_train_transformed = selector.transform(features_train_transformed).toarray()\n",
    "    features_test_transformed  = selector.transform(features_test_transformed).toarray()\n",
    "\n",
    "    ### info on the data\n",
    "    print(\"no. of Chris training emails:\", sum(labels_train))\n",
    "    print(\"no. of Sara training emails:\", len(labels_train)-sum(labels_train))\n",
    "    \n",
    "    return features_train_transformed, features_test_transformed, labels_train, labels_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "UnpicklingError",
     "evalue": "the STRING opcode argument must be quoted",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-386413d55922>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m### and testing datasets, respectively\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;31m### labels_train and labels_test are the corresponding item labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mfeatures_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m#########################################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-614075ebf46b>\u001b[0m in \u001b[0;36mpreprocess\u001b[1;34m(words_file, authors_file)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[0mwords_file_handler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m     \u001b[0mword_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords_file_handler\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#cPickle.load(words_file_handler)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m     \u001b[0mwords_file_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnpicklingError\u001b[0m: the STRING opcode argument must be quoted"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "    this is the code to accompany the Lesson 1 (Naive Bayes) mini-project \n",
    "\n",
    "    use a Naive Bayes Classifier to identify emails by their authors\n",
    "    \n",
    "    authors and labels:\n",
    "    Sara has label 0\n",
    "    Chris has label 1\n",
    "    \n",
    "\"\"\"\n",
    "    \n",
    "import sys\n",
    "from time import time\n",
    "sys.path.append(r\"C:\\Users\\Gordon\\Documents\\Projects\\ud120-projects\\tools\")\n",
    "\n",
    "### features_train and features_test are the features for the training\n",
    "### and testing datasets, respectively\n",
    "### labels_train and labels_test are the corresponding item labels\n",
    "features_train, features_test, labels_train, labels_test = preprocess()\n",
    "\n",
    "#########################################################\n",
    "### your code goes here ###\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB as GB\n",
    "\n",
    "clf = GB()\n",
    "t0 = time()\n",
    "clf.fit(features_train,labels_train)\n",
    "print(\"training time:\", round(time()-t0, 3), \"s\")\n",
    "t1 = time()\n",
    "clf.predict(features_train)\n",
    "print(\"predicting time:\", round(time()-t1, 3), \"s\")\n",
    "\n",
    "accuracy_score = clf.score(features_test,labels_test)\n",
    "print(accuracy_score)\n",
    "\n",
    "#########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "    this is the code to accompany the Lesson 2 (SVM) mini-project\n",
    "\n",
    "    use an SVM to identify emails from the Enron corpus by their authors\n",
    "    \n",
    "    Sara has label 0\n",
    "    Chris has label 1\n",
    "\n",
    "\"\"\"\n",
    "    \n",
    "import sys\n",
    "from time import time\n",
    "sys.path.append(r\"C:\\Users\\Gordon\\Documents\\Projects\\ud120-projects\\tools\")\n",
    "\n",
    "### features_train and features_test are the features for the training\n",
    "### and testing datasets, respectively\n",
    "### labels_train and labels_test are the corresponding item labels\n",
    "features_train, features_test, labels_train, labels_test = preprocess()\n",
    "\n",
    "#########################################################\n",
    "### your code goes here ###\n",
    "\n",
    "features_train = features_train[:len(features_train)/100] \n",
    "labels_train = labels_train[:len(labels_train)/100] \n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC(kernel='linear')\n",
    "t0 = time()\n",
    "clf.fit(features_train,labels_train)\n",
    "print \"training time:\", round(time()-t0, 3), \"s\"\n",
    "t1 = time()\n",
    "pred=clf.predict(features_test)\n",
    "print(\"predicting time:\", round(time()-t1, 3), \"s\")\n",
    "print(clf.score(features_test,labels_test))\n",
    "#########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "    this is the code to accompany the Lesson 3 (decision tree) mini-project\n",
    "\n",
    "    use an DT to identify emails from the Enron corpus by their authors\n",
    "    \n",
    "    Sara has label 0\n",
    "    Chris has label 1\n",
    "\n",
    "\"\"\"\n",
    "    \n",
    "import sys\n",
    "from time import time\n",
    "sys.path.append(r\"C:\\Users\\Gordon\\Documents\\Projects\\ud120-projects\\tools\")\n",
    "\n",
    "### features_train and features_test are the features for the training\n",
    "### and testing datasets, respectively\n",
    "### labels_train and labels_test are the corresponding item labels\n",
    "features_train, features_test, labels_train, labels_test = preprocess()\n",
    "\n",
    "#########################################################\n",
    "### your code goes here ###\n",
    "from sklearn.tree import DecisionTreeClassifier as DTC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf = DTC(min_samples_split=40)\n",
    "clf.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "accuracy = accuracy_score(pred,labels_test)\n",
    "print(accuracy)\n",
    "#########################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
